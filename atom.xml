<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>樱花飘落之时</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yhcheer.com/"/>
  <updated>2018-10-24T00:48:06.381Z</updated>
  <id>http://yhcheer.com/</id>
  
  <author>
    <name>yh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>用阿里云搭建Hadoop集群</title>
    <link href="http://yhcheer.com/2018/10/23/hadoop-from-zero/"/>
    <id>http://yhcheer.com/2018/10/23/hadoop-from-zero/</id>
    <published>2018-10-23T14:10:33.000Z</published>
    <updated>2018-10-24T00:48:06.381Z</updated>
    
    <content type="html"><![CDATA[<p>《大数据存储》课程好像过半了，赶紧来搭个环境。</p><p>这次用了3台阿里云ECS服务器（学生机）来完成这次的环境搭建。由于是三个不同的账号（每个账号的学生优惠只能有一个实例），所以走的是外网IP通道，和网上大部分教程有一定的区别。</p><a id="more"></a><h2 id="一、HADOOP集群搭建"><a href="#一、HADOOP集群搭建" class="headerlink" title="一、HADOOP集群搭建"></a>一、HADOOP集群搭建</h2><h3 id="1-服务器准备"><a href="#1-服务器准备" class="headerlink" title="1 服务器准备"></a>1 服务器准备</h3><p>阿里云ESC服务器 1 vCPU 2 GB (I/O优化) ecs.n4.small 1Mbps </p><p>默认系统选的Centos 7.4 64bit</p><p>阿里云已经导入学信网系统，学生优惠9.5/月，你值得拥有</p><h3 id="2-网络环境准备"><a href="#2-网络环境准备" class="headerlink" title="2 网络环境准备"></a>2 网络环境准备</h3><p>阿里云自动分配公网IP和私网IP，记住即可</p><p>阿里云的安全组设置默认只开启22端口用于SSH，以及3389端口用于远程登录</p><p>对于搭hadoop集群的我们肯定是不够的，如果你不太了解hadoop的端口配置，就到阿里云控制台上在你的实例的安全组上，添加如下一步到位的规则：</p><p>规则方向-出方向和入方向，协议类型-全部，授权类型-地址段访问，授权对象-0.0.0.0/0</p><p>当然这样是很不安全的，但对于新手来说，省了很多麻烦，建议后期手动修改安全组设置。</p><h3 id="3-服务器系统设置"><a href="#3-服务器系统设置" class="headerlink" title="3 服务器系统设置"></a>3 服务器系统设置</h3><p>3.1 添加HADOOP用户</p><p><del>不添加。</del>我是用root用户来搭建。</p><p><strong>PS. 我第一次搭的时候，使用的是HADOOP用户，但尝试了各种方法，都无法成功在HADOOP用户下进行ssh免密，导致最后跑集群的时候出错。</strong></p><p>3.2 分配root权限</p><p><del>root用户无需再分配</del></p><p>3.3 同步时间</p><p><del>阿里云无需同步时间</del></p><p>3.4 设置主机名（重要）</p><p><code>sudo nano /etc/hostname</code></p><p>我习惯用nano，没有的话装一下<code>yum install nano</code></p><p>如果是自己的主机的话直接在“阿里云实例设置-修改信息-重启实例”也能改。</p><p>三台机器主机名分别设y为：</p><ul><li>hdp-node-01</li><li>hdp-node-02</li><li>hdp-node-03</li></ul><p>3.5 域名映射（重要）</p><p>将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”</p><p><code>sudo nano /etc/hosts</code></p><p>在<strong>文件最下方</strong>添加如下信息，我这里用外网IP。如果是在同一个账号下的三个实例，可以选择走内网IP通道，速度上应该会快很多。</p><ul><li>本机<strong>内网IP</strong> hdp-node-01</li><li>从机外网IP hdp-node-02</li><li>从机外网IP hdp-node-03</li></ul><p><strong>PS. 这里一开始我用的都是外网IP，最后报错，原因大概是阿里云的外网IP冲突问题，因此改为内网IP。注意只有主机的hosts配置的第一个节点（本机）是内网IP，并且另外几台从机的hosts配置都是使用外网IP不用改变。</strong></p><p>3.6 配置ssh免密登录（重要）</p><p><code>ssh-keygen</code>利用ssh-keygen生成密钥</p><p><code>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code>加入到授权，可以免密ssh自己</p><p>把密匙公钥发送给别的节点，已达到免密的效果，发送时要输入对面节点的密码</p><p><code>scp ~/.ssh/id_rsa.pub root@hdp-node-02:~/.ssh</code>将id_rsa.pub拷贝到hdp-node-02节点上</p><p><code>scp ~/.ssh/id_rsa.pub root@hdp-node-03:~/.ssh</code>将id_rsa.pub拷贝到hdp-node-03节点上</p><p><strong>换到hdp-node-02和hdp-node-03上操作：</strong></p><p><code>cat ~/.ssh/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</code>把刚才的密匙加入到授权</p><p><strong>回到hdp-node-01上操作：</strong></p><p>测试<code>ssh hdp-node-02</code>成功！如果还需要输入密码则免密失败。</p><p><code>logout</code>退出刚才的ssh</p><p><strong>PS. 后来调试bug的时候，我把所有节点相互之间的ssh免密也实现了，理论上应该只需要主机ssh所有从机即可。</strong></p><p>3.7 配置防火墙</p><p><code>systemctl stop firewalld</code>关闭centos7防火墙</p><h3 id="4-JDK环境安装"><a href="#4-JDK环境安装" class="headerlink" title="4 JDK环境安装"></a>4 JDK环境安装</h3><p>JDK是HADOOP的必要环境</p><p>下载jdk1.8，可以用wget方法，我就用FileZilla传上去再解压好了</p><p>放到/usr文件夹下，解压</p><p><code>tar -zxf jdk-8u191-linux-x64.tar.gz</code></p><p>重命名一下文件夹名字为java（非必须）</p><p><code>mv jdk1.8.0_191 java</code></p><p>配置环境变量<code>nano /etc/profile</code>，在<strong>文件最下方</strong>添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><p>生效环境<code>source /etc/profile</code></p><p>测试<code>java -version</code>，成功则显示版本号</p><p>重复以上步骤在每个从机上执行</p><h3 id="5-hadoop安装和部署"><a href="#5-hadoop安装和部署" class="headerlink" title="5 hadoop安装和部署"></a>5 hadoop安装和部署</h3><p>下载、解压。同上。</p><p>重命名一下（非必须）</p><p><code>mv hadoop2.7.7 hadoop</code></p><p><strong>PS. 我这里使用的是hadoop 2.7.7版本，注意hadoop 3与hadoop 2的改动比较大，包括端口、命令、以及一些配置等，注意区别。</strong></p><p>配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java</span><br><span class="line">export PATH=PATH:JAVA_HOME/bin</span><br><span class="line">export HADOOP_HOME=/usr/hadoop</span><br><span class="line">export PATH=PATH:HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><p>生效环境<code>source /etc/profile</code></p><p>测试<code>hadoop version</code>显示版本号，则成功</p><h3 id="6-开始部署hadoop"><a href="#6-开始部署hadoop" class="headerlink" title="6 开始部署hadoop"></a>6 开始部署hadoop</h3><p>进入hadoop安装目录下的<strong>子目录</strong>/etc/hadoop</p><p><code>cd /usr/hadoop/etc/hadoop</code></p><ul><li>配置JAVA路径</li></ul><p><code>nano hadoop-env.sh</code>找到下面写有JAVA_HOME的地方，修改JAVA路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># The java implementation to use.</span><br><span class="line">export JAVA_HOME=/usr/java</span><br></pre></td></tr></table></figure><ul><li>配置core-site.xml</li></ul><p>集群全局参数，用于定义系统级别的参数，如HDFS  URL、Hadoop的临时目录等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hdp-node-01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>fs.defaultFS</td><td>file:///</td><td>文件系统主机和端口</td></tr><tr><td>2</td><td>io.file.buffer.size</td><td>4096</td><td>流文件的缓冲区大小</td></tr><tr><td>3</td><td>hadoop.tmp.dir</td><td>/tmp/hadoop-${user.name}</td><td>临时文件夹</td></tr></tbody></table><ul><li>配置hdfs-site.xml</li></ul><p>HDFS参数，如名称节点和数据节点的存放位置、文件副本的个数、文件读取权限等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-02:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.https-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-02:50091<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>dfs.namenode.secondary.http-address</td><td>0.0.0.0:50090</td><td>定义HDFS对应的HTTP服务器地址和端口</td></tr><tr><td>2</td><td>dfs.namenode.name.dir</td><td>file://${hadoop.tmp.dir}/dfs/name</td><td>定义DFS的名称节点在本地文件系统的位置</td></tr><tr><td>3</td><td>dfs.datanode.data.dir</td><td>file://${hadoop.tmp.dir}/dfs/data</td><td>定义DFS数据节点存储数据块时存储在本地文件系统的位置</td></tr><tr><td>4</td><td>dfs.replication</td><td>3</td><td>缺省的块复制数量</td></tr><tr><td>5</td><td>dfs.webhdfs.enabled</td><td>true</td><td>是否通过http协议读取hdfs文件，如果选是，则集群安全性较差</td></tr></tbody></table><ul><li>配置mapred-site.xml</li></ul><p>Mapreduce参数，包括JobHistory Server和应用程序参数两部分，如reduce任务的默认个数、任务所能够使用内存的默认上下限等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>mapreduce.framework.name</td><td>local</td><td>取值local、classic或yarn其中之一，如果不是yarn，则不会使用YARN集群来实现资源的分配</td></tr><tr><td>2</td><td>mapreduce.jobhistory.address</td><td>0.0.0.0:10020</td><td>定义历史服务器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录</td></tr><tr><td>3</td><td>mapreduce.jobhistory.webapp.address</td><td>0.0.0.0:19888</td><td>定义历史服务器web应用访问的地址和端口</td></tr></tbody></table><ul><li>配置yarn-site.xml</li></ul><p>集群资源管理系统参数，配置 ResourceManager，NodeManager 的通信端口，web监控端口等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- RM的hostname --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定Yarn的老大(ResourceManager)的地址--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>yarn.resourcemanager.address</td><td>0.0.0.0:8032</td><td>ResourceManager 提供给客户端访问的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</td></tr><tr><td>2</td><td>yarn.resourcemanager.scheduler.address</td><td>0.0.0.0:8030</td><td>ResourceManager提供给ApplicationMaster的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等</td></tr><tr><td>3</td><td>yarn.resourcemanager.resource-tracker.address</td><td>0.0.0.0:8031</td><td>ResourceManager 提供给NodeManager的地址。NodeManager通过该地址向RM汇报心跳，领取任务等</td></tr><tr><td>4</td><td>yarn.resourcemanager.admin.address</td><td>0.0.0.0:8033</td><td>ResourceManager 提供给管理员的访问地址。管理员通过该地址向RM发送管理命令等。</td></tr><tr><td>5</td><td>yarn.resourcemanager.webapp.address</td><td>0.0.0.0:8088</td><td>ResourceManager对web 服务提供地址。用户可通过该地址在浏览器中查看集群各类信息</td></tr><tr><td>6</td><td>yarn.nodemanager.aux-services</td><td></td><td>通过该配置项，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的，这样就可以在NodeManager上扩展自己的服务。</td></tr></tbody></table><ul><li>配置slaves</li></ul><p><code>nano slaves</code></p><p>hdp-node-02<br>hdp-node-03</p><ul><li>配置masters</li></ul><p><code>nano masters</code></p><p>hdp-node-01</p><p><strong>PS. 其实可以在一台机子上安装和配置好，然后用scp命令直接复制整个文件夹给从机。但阿里云外网IP间传输实在是太慢了！</strong></p><h3 id="7-启动集群"><a href="#7-启动集群" class="headerlink" title="7 启动集群"></a>7 启动集群</h3><ul><li>初始化HDFS</li></ul><p><code>hdfs namenode -format</code></p><ul><li>启动HDFS以及YARN</li></ul><p><code>bash start-all.sh</code></p><p>集群启动完毕。在浏览器上可观察启动状况</p><p>输入<code>主机IP:50070</code>，查看大体配置情况。主要注意存活节点数，我这里是2个slaves。</p><p><img src="http://ph25hhyzh.bkt.clouddn.com/1540315053705.png" alt="1540315053705"></p><p>输入<code>主机IP:8088</code>，可查看当前运行情况。这里我在跑一个wordcount的demo，可看到进度情况。</p><p><img src="http://ph25hhyzh.bkt.clouddn.com/1540314812172.png" alt="1540314812172"></p><ul><li>建立input目录</li></ul><p><code>hadoop fs -mkdir -p /wordcount/input</code></p><ul><li>放入文件到该目录下</li></ul><p><code>hadoop fs -put /usr/hello.txt /wordcount/input</code></p><ul><li>跑demo</li></ul><p><code>cd ./share/hadoop/mapreduce/</code></p><p><code>hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input/hello.txt output2</code></p><p>在控制台中可看到，表示运行成功：</p><p><img src="http://ph25hhyzh.bkt.clouddn.com/1540315291480.png" alt="1540315291480"></p><p>我的hello.txt的内容是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br></pre></td></tr></table></figure><p>取出wordcount统计结果：</p><p><img src="http://ph25hhyzh.bkt.clouddn.com/1540315844610.png" alt="1540315844610"></p><p>这就是Hadoop世界的HelloWorld代码，我们环境搭建也随之完成。</p><p>参考：</p><p>阿里云内网IP搭建：<a href="https://blog.csdn.net/bqw18744018044/article/details/79103931" target="_blank" rel="noopener">https://blog.csdn.net/bqw18744018044/article/details/79103931</a></p><p>阿里云内网IP搭建：<a href="https://blog.csdn.net/QianZhaoVic/article/details/83150703" target="_blank" rel="noopener">https://blog.csdn.net/QianZhaoVic/article/details/83150703</a></p><p>hadoop参数：<a href="https://blog.csdn.net/lydia88/article/details/79449656" target="_blank" rel="noopener">https://blog.csdn.net/lydia88/article/details/79449656</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;《大数据存储》课程好像过半了，赶紧来搭个环境。&lt;/p&gt;
&lt;p&gt;这次用了3台阿里云ECS服务器（学生机）来完成这次的环境搭建。由于是三个不同的账号（每个账号的学生优惠只能有一个实例），所以走的是外网IP通道，和网上大部分教程有一定的区别。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://yhcheer.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://yhcheer.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hadoop" scheme="http://yhcheer.com/tags/Hadoop/"/>
    
      <category term="JAVA]" scheme="http://yhcheer.com/tags/JAVA/"/>
    
  </entry>
  
  <entry>
    <title>Leetcode中关于栈的小结（上）</title>
    <link href="http://yhcheer.com/2018/10/21/leetcode-stack/"/>
    <id>http://yhcheer.com/2018/10/21/leetcode-stack/</id>
    <published>2018-10-21T12:46:00.000Z</published>
    <updated>2018-10-24T00:50:41.270Z</updated>
    
    <content type="html"><![CDATA[<p>这次按标签，从栈专题开始刷起，大概一周做一次总结。</p><a id="more"></a><table><thead><tr><th>#</th><th><strong>题名</strong></th><th>题解</th><th><strong>通过率</strong></th><th><strong>难度</strong></th></tr></thead><tbody><tr><td>232</td><td><a href="https://leetcode-cn.com/problems/implement-queue-using-stacks" target="_blank" rel="noopener">用栈实现队列</a></td><td></td><td>54.8%</td><td>简单</td></tr><tr><td>496</td><td><a href="https://leetcode-cn.com/problems/next-greater-element-i" target="_blank" rel="noopener">下一个更大元素 I</a></td><td></td><td>54.7%</td><td>简单</td></tr><tr><td>682</td><td><a href="https://leetcode-cn.com/problems/baseball-game" target="_blank" rel="noopener">棒球比赛</a></td><td></td><td>53.1%</td><td>简单</td></tr><tr><td>225</td><td><a href="https://leetcode-cn.com/problems/implement-stack-using-queues" target="_blank" rel="noopener">用队列实现栈</a></td><td></td><td>49.1%</td><td>简单</td></tr><tr><td>155</td><td><a href="https://leetcode-cn.com/problems/min-stack" target="_blank" rel="noopener">最小栈</a></td><td></td><td>45.0%</td><td>简单</td></tr><tr><td>844</td><td><a href="https://leetcode-cn.com/problems/backspace-string-compare" target="_blank" rel="noopener">比较含退格的字符串</a></td><td></td><td>42.5%</td><td>简单</td></tr><tr><td>20</td><td><a href="https://leetcode-cn.com/problems/valid-parentheses" target="_blank" rel="noopener">有效的括号</a></td><td></td><td>33.0%</td><td>简单</td></tr><tr><td>94</td><td><a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal" target="_blank" rel="noopener">二叉树的中序遍历</a></td><td></td><td>61.5%</td><td>中等</td></tr><tr><td>144</td><td><a href="https://leetcode-cn.com/problems/binary-tree-preorder-traversal" target="_blank" rel="noopener">二叉树的前序遍历</a></td><td></td><td>52.6%</td><td>中等</td></tr><tr><td>341</td><td><a href="https://leetcode-cn.com/problems/flatten-nested-list-iterator" target="_blank" rel="noopener">扁平化嵌套列表迭代器</a></td><td></td><td>50.8%</td><td>中等</td></tr><tr><td>173</td><td><a href="https://leetcode-cn.com/problems/binary-search-tree-iterator" target="_blank" rel="noopener">二叉搜索树迭代器</a></td><td></td><td>49.7%</td><td>中等</td></tr><tr><td>739</td><td><a href="https://leetcode-cn.com/problems/daily-temperatures" target="_blank" rel="noopener">每日温度</a></td><td></td><td>48.3%</td><td>中等</td></tr><tr><td>856</td><td><a href="https://leetcode-cn.com/problems/score-of-parentheses" target="_blank" rel="noopener">括号的分数</a></td><td></td><td>44.7%</td><td>中等</td></tr><tr><td>103</td><td><a href="https://leetcode-cn.com/problems/binary-tree-zigzag-level-order-traversal" target="_blank" rel="noopener">二叉树的锯齿形层次遍历</a></td><td></td><td>42.9%</td><td>中等</td></tr><tr><td>503</td><td><a href="https://leetcode-cn.com/problems/next-greater-element-ii" target="_blank" rel="noopener">下一个更大元素 II</a></td><td></td><td>40.7%</td><td>中等</td></tr><tr><td>150</td><td><a href="https://leetcode-cn.com/problems/evaluate-reverse-polish-notation" target="_blank" rel="noopener">逆波兰表达式求值</a></td><td></td><td>39.1%</td><td>中等</td></tr><tr><td>331</td><td><a href="https://leetcode-cn.com/problems/verify-preorder-serialization-of-a-binary-tree" target="_blank" rel="noopener">验证二叉树的前序序列化</a></td><td></td><td>38.8%</td><td>中等</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这次按标签，从栈专题开始刷起，大概一周做一次总结。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yhcheer.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="Leetcode 栈 算法 JAVA" scheme="http://yhcheer.com/tags/Leetcode-%E6%A0%88-%E7%AE%97%E6%B3%95-JAVA/"/>
    
  </entry>
  
  <entry>
    <title>实现一个光线追踪渲染器</title>
    <link href="http://yhcheer.com/2018/10/20/ray-tarcing/"/>
    <id>http://yhcheer.com/2018/10/20/ray-tarcing/</id>
    <published>2018-10-20T14:48:33.000Z</published>
    <updated>2018-10-24T00:48:36.461Z</updated>
    
    <content type="html"><![CDATA[<p>想用JAVA写一个光线追踪渲染器。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想用JAVA写一个光线追踪渲染器。&lt;/p&gt;
    
    </summary>
    
      <category term="算法" scheme="http://yhcheer.com/categories/%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="计算机图形学 光线追踪" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6-%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/"/>
    
  </entry>
  
  <entry>
    <title>故梦</title>
    <link href="http://yhcheer.com/2018/10/20/hello-world/"/>
    <id>http://yhcheer.com/2018/10/20/hello-world/</id>
    <published>2018-10-20T01:48:33.000Z</published>
    <updated>2018-10-24T00:49:33.838Z</updated>
    
    <content type="html"><![CDATA[<p>时隔9月，我的博客终于翻新了。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时隔9月，我的博客终于翻新了。&lt;/p&gt;
    
    </summary>
    
      <category term="杂谈" scheme="http://yhcheer.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="心情" scheme="http://yhcheer.com/tags/%E5%BF%83%E6%83%85/"/>
    
  </entry>
  
</feed>
