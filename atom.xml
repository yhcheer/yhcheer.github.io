<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>樱花飘落之时</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yhcheer.com/"/>
  <updated>2018-12-29T13:23:56.565Z</updated>
  <id>http://yhcheer.com/</id>
  
  <author>
    <name>yh</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【《计算机图形学基础》提炼总结】（三）材质反射属性模型BRDF</title>
    <link href="http://yhcheer.com/2018/12/27/graph-note-03/"/>
    <id>http://yhcheer.com/2018/12/27/graph-note-03/</id>
    <published>2018-12-27T08:22:00.000Z</published>
    <updated>2018-12-29T13:23:56.565Z</updated>
    
    <content type="html"><![CDATA[<p>第一章主要讲解了计算机图形学的<strong>基本概念</strong>，包括定义以及和另一些相近研究方向的区别，并详细讲解了计算机图形学的<strong>历史与发展进程</strong>，最后展示了<strong>最新的图形学研究成果</strong>。作为绪论的一章，重在引起同学们的兴趣。</p><a id="more"></a><p>这节课先回顾了一下一些数学和辐射度量学的基本概念，</p><p>课程主页：<a href="https://cg.cs.tsinghua.edu.cn/course/resource.htm" target="_blank" rel="noopener">https://cg.cs.tsinghua.edu.cn/course/resource.htm</a></p><p>本系列笔记导航：<a href="http://yhcheer.com/2018/12/21/graph-note/">http://yhcheer.com/2018/12/21/graph-note/</a></p><h2 id="第三讲-材质反射属性模型BRDF"><a href="#第三讲-材质反射属性模型BRDF" class="headerlink" title="第三讲 材质反射属性模型BRDF"></a>第三讲 材质反射属性模型BRDF</h2><ul><li>一些基本概念复习</li></ul><p>球面坐标（Spherical Coordinate）</p><p>立体角（Solid Angle）</p><p>投影面积（Foreshortened Area）</p><p>光能（Radiant Energy）</p><p>光通量（Radiant Flux）</p><p>辉度（Irradiance）</p><p>发光强度（Radiant Intensity）</p><p>光亮度（Radiance）</p><ul><li>什么是BRDF？</li></ul><p>为了研究光线如何被物体反射。</p><p>BRDF是关于入射光方向和反射光方向的四维实值函数，它等于<strong>反射方向的光亮度</strong>和<strong>入射方向入射光的辉度</strong>之比。</p><p><img src="https://gss0.bdstatic.com/-4o3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike52%2C5%2C5%2C52%2C17/sign=de21a67d0cd79123f4ed9c26cc5d32e7/0ff41bd5ad6eddc4457b428e39dbb6fd52663322.jpg" alt="BRDF公式"></p><ul><li>为什么BRDF是光亮度和辉度之比，而不是光亮度和光亮度之比活着辉度和辉度之比？</li></ul><p>我们假设人眼是从反射方向上看物体，而看到的就是反射光线上的<strong>光亮度</strong>，但是不同方向的入射光照到该点都可能从这个反射方向上反射出来，因此对于入射光，我们需要对面积积分，因此相当于光亮度对面积积分用<strong>辉度</strong>来表示。</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1546064003017.png" alt="1546064003017"></p><ul><li>BRDF的性质？</li></ul><p><strong>可逆性</strong>（Reciprocity）：光路可逆性，交换入射光和反射光不会改变BRDF的值。</p><p><strong>能量守恒</strong>（Energy conservation）：入射光的能量与出射光的总能量应该相等。</p><blockquote><p>Q_in = Q_reflected + Q_absorb + Q_transmitted</p></blockquote><p>由上式可知：Q_reflected &lt;= Q_in</p><p>故可得</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1546065992133.png" alt="1546065992133"></p><p><strong>渲染方程</strong>（Rendering Equation）:用于计算环境光照明下的<strong>反射光的光亮度</strong>，它可以写成<strong>不同角度下入射光的光亮度</strong>乘以<strong>BRDF的积分</strong>。</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1546066221836.png" alt="1546066221836"></p><ul><li>BRDF的模型？</li></ul><p>为了方便和高效地使用BRDF数据，它往往被组织成参数化的数值模型。</p><p><strong>经验模型</strong>（Empirical Models）</p><p><strong>基于物理的模型</strong>（Physical-based Models）</p><p><strong>数据表达的模型</strong>（Data-driven Models）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;第一章主要讲解了计算机图形学的&lt;strong&gt;基本概念&lt;/strong&gt;，包括定义以及和另一些相近研究方向的区别，并详细讲解了计算机图形学的&lt;strong&gt;历史与发展进程&lt;/strong&gt;，最后展示了&lt;strong&gt;最新的图形学研究成果&lt;/strong&gt;。作为绪论的一章，重在引起同学们的兴趣。&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="BRDF" scheme="http://yhcheer.com/tags/BRDF/"/>
    
  </entry>
  
  <entry>
    <title>【《计算机图形学基础》提炼总结】（二）颜色、图像基础知识及光照模型</title>
    <link href="http://yhcheer.com/2018/12/27/graph-note-02/"/>
    <id>http://yhcheer.com/2018/12/27/graph-note-02/</id>
    <published>2018-12-26T16:59:00.000Z</published>
    <updated>2018-12-27T08:22:34.309Z</updated>
    
    <content type="html"><![CDATA[<p>这一章主要从<strong>颜色和光的基本概念</strong>，扩展到色彩空间的概念，详细介绍了几个常用的<strong>色彩空间</strong>。然后讲解了一些<strong>图像</strong>的基本知识，最后讲了一些<strong>光照模型</strong>的知识。主要是一些零散的概念，为后面的知识作铺垫。</p><a id="more"></a><p>课程主页：<a href="https://cg.cs.tsinghua.edu.cn/course/resource.htm" target="_blank" rel="noopener">https://cg.cs.tsinghua.edu.cn/course/resource.htm</a></p><p>本系列笔记导航：<a href="http://yhcheer.com/2018/12/21/graph-note/">http://yhcheer.com/2018/12/21/graph-note/</a></p><h2 id="第二讲-颜色模型、图像基本知识、Phong光照模型"><a href="#第二讲-颜色模型、图像基本知识、Phong光照模型" class="headerlink" title="第二讲 颜色模型、图像基本知识、Phong光照模型"></a>第二讲 颜色模型、图像基本知识、Phong光照模型</h2><h3 id="2-1-颜色模型"><a href="#2-1-颜色模型" class="headerlink" title="2.1 颜色模型"></a>2.1 颜色模型</h3><ul><li>什么是色彩？</li></ul><p><strong>色彩</strong>是对不同波长的光的能量的感知。</p><ul><li>什么是光及光的谱分布？</li></ul><p><strong>光</strong>（Light）：是由不同波长的电磁波按照某种能量分布混合叠加而成。如白光（由所有可见波长的电磁波以相同的强度混合）。</p><p><strong>谱分布</strong>（spectral distribution）：光在各个可见波长分量的强度分布函数。如下图所示的谱分布，各可见波长分布形成一条曲线，最终形成如图下方的紫色。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/Qm7*.vX.tq1Wn7LdweKZg98P*vPVzNd4B.rEr1rEA4Q!/r/dDQBAAAAAAAA&amp;bo=tgGWArYBlgIDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545833706809"></p><p><strong>异谱同色现象</strong>（different spectrum distribution with the same color）：色彩也可用谱分布函数来表示，但不同的谱分布可能对应同一种色彩。故提出类似RGB色彩空间的概念。</p><ul><li>什么是RGB色彩空间，为什么以RGB作为三个基本色彩？</li></ul><p>色彩使用<strong>三通道RGB向量（r,g,b）</strong>表示。对每个通道可以单独操作，可以分别归整化到[0,1]内的浮点数，如果使用8bit进行存储，则通常取[0,255]内的整数。</p><p><code>色彩C=r·R+g·G+b·B</code></p><p>以RGB作为三个基本色彩，是因为人眼的视网膜中有三种锥状视觉细胞，分别对红绿蓝三种光最为敏感。</p><p><strong>RGB空间的缺点</strong>：有一部分空间是无法显示的。如下图所示，红色光取值百分比是负数。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/FKT3x2iQpxkmO.f1UKsQv9BiTK.XgY3icydgUmxAsa0!/r/dLgAAAAAAAAA&amp;bo=kQFIAZEBSAEDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545835327506"></p><ul><li>什么是CMY色彩空间？</li></ul><p><strong>CMY色彩空间</strong>：基本颜色换成青（<strong>C</strong>yan）, 品红（<strong>M</strong>agenta）和黄（<strong>Y</strong>ellow），它们分别是红绿蓝的<strong>补色</strong>。CMY是“<strong>减色系统</strong>”，像素值越大，颜色越灰暗（趋向黑色），与RGB正好相反。应用场景：印刷出版业。</p><ul><li>什么是HSV色彩空间？</li></ul><p><strong>HSV色彩空间</strong>：真彩色的颜色总数为16,777,216种（256x256x256），用RGB色彩空间来描述和定位较为困难，故HSV提供了一个直观的方法对色彩进行准确的选择。应用场景：图象处理、分形图像和光线追踪等，特别是艺术领域。</p><p><strong>H</strong>ue（色调/色相）：描述色彩的本征属性，如红橙黄绿青蓝紫等。</p><p><strong>S</strong>aturation（饱和度/纯度）：饱和度越低，色彩越白。</p><p><strong>V</strong>alue of brightness（亮度）：亮度越黑，色彩越黑。</p><p>色彩直观显示如下图：</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/ywqw13DNn40m.4olM2TWPkBYXOmFdEG3j8ltTzJSQBA!/r/dL4AAAAAAAAA&amp;bo=SAEOAUgBDgEDCSw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545836349793"></p><ul><li>什么是CIE XYZ色彩空间？</li></ul><p>CIE假定人对色彩的感知是线性的，因此对上面的rgb色域图进行了线性变换，将可见光色域变换到正数区域内，改用三个假想的原色X、Y、 Z建立了一个新的色度系统。因此<strong>CIE XYZ色彩空间</strong>可以表示<strong>所有可感知色彩</strong>（解决RGB色彩空间缺陷）。应用场景：多用于色彩科学的研究。</p><p>其中：</p><p><code>x=X/(X+Y+Z)</code></p><p><code>y=Y/(X+Y+Z)</code></p><p><code>z=Z/(X+Y+Z)=1-x-y</code></p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/CIE1931xy_blank.svg/300px-CIE1931xy_blank.svg.png" alt="wiki CIE XYZ"></p><p>这里的颜色只是示意,事实上没有设备能完全还上面所有的自然色域。在该图中任意选定两点，两点间直线上的颜色可由这两点的颜色混合成。给定三个点，三点构成的三角形内颜色可由这三个点颜色混合成。</p><h3 id="2-2-图像基本知识"><a href="#2-2-图像基本知识" class="headerlink" title="2.2 图像基本知识"></a>2.2 图像基本知识</h3><ul><li>什么是三角网格？</li></ul><p><strong>三角网格</strong>由<strong>顶点</strong>和<strong>三角面片</strong>组成。</p><p><strong>顶点</strong>集合 <code>V = (v1, v2, v3 ... vn)</code></p><p><strong>面片</strong>集合<code>F = (f1, f2, f3 ... fn)</code></p><p>其中，每个F中的每个面片fi都是由V中的顶点构成的三角形，如<code>f1 =  (v1, v2, v3)</code>，可以使用顶点的编号进行索引。</p><ul><li>怎么计算<strong>顶点的法向量</strong>？</li></ul><p>可以通过周围的所有三角面片的法向量通过加权叠加计算。</p><p>按算数平均计算：<code>N_v= (N_f1+N_f2+ ... + N_fm)/m</code></p><p>按面积加权平均计算：<code>N_v= (S_f1·N_f1+S_f2·N_f2+ ... + S_fm·N_fm)/(S_f1+S_f2+ ... +S_fm)</code></p><p>按角度加权平均计算：<code>N_v= (Ang_f1·1_fm+Ang_f2·N_f2+ ... + Ang_fm·N_fm)/(Ang_f1+ ... +Ang_fm)</code></p><h3 id="2-3-光照模型"><a href="#2-3-光照模型" class="headerlink" title="2.3 光照模型"></a>2.3 光照模型</h3><ul><li>局部光照模型和全局光照模型的区别？</li></ul><p><strong>局部光照模型</strong>（Local Lighting）：物体直接受光源影响所产生的光照效果</p><p><strong>全局光照模型</strong>（Global Lighting）：不止考虑直接照明还考虑间接照明，包括阴影、反射、折射等</p><ul><li>光照模型的历史？</li></ul><p>1967年，Wylie第一次在显示物体时，加入光照效果，认为光的强度与物体到光源的距离成反比。</p><p>1970年，Bouknight提出第一个光反射模型。Lambert diffuse reflection（漫发射） + ambient (No specular lighting)（环境光）</p><p>1971年，Gourand突出漫反射模型加插值思想。Lambert diffuse + Bicentric interpolation</p><p>1975年，Phong提出第一个有影响的光照模型。Diffuse（漫发射）ambient（环境光）+ specular（高光）</p><ul><li>光线传播的能量守恒定律？</li></ul><blockquote><p>I_i = I_d + I_s + I_t + I_v</p></blockquote><p>其中，</p><p>I_i入射光的能量</p><p>I_d漫反射（diffuse reflection）光的能量</p><p>I_s镜面反射（specular reflection）光的能量</p><p>I_t折射（refraction）光的能量</p><p>I_v被介质和物体所吸收的能量</p><ul><li>什么是立体角？</li></ul><p><strong>立体角</strong>（Solid Angle）：衡量物体相对于某一视点P的视角的大小，最大为4Pi。单位sr。</p><blockquote><p>dw = ds / r^2</p></blockquote><ul><li>什么是光通量？</li></ul><p><strong>光通量/辐射通量</strong>（Luminous/Radiant Flux）：单位时间内通过面元dS的光能量，记为dF。单位W。</p><ul><li>什么是发光强度？</li></ul><p><strong>发光强度/辐射强度</strong>（Radiant Intensity）：单位立体角内的光通量，记为I。单位W/sr。</p><ul><li>什么是光亮度？</li></ul><p><strong>光亮度/辐射率</strong>（Radiance）：单位投影面积和单位立体角内的光通量，记为L。单位W/sr·m^2</p><ul><li>什么是辉度？</li></ul><p><strong>辉度/辐照度</strong>（Irradiance）：单位时间内单位面积的光通量，记为E。单位W/m^2。</p><ul><li>什么是Phong模型？</li></ul><p><strong>Phong模型</strong>支持点光源和方向光源。是局部光照模型，可分为三个部分：漫反射+镜面反射+环境光。</p><p>Phong模型的<strong>几何表达</strong>如下图，其中L是<strong>入射光</strong>，R是<strong>反射光</strong>，N是<strong>法向量</strong>，V是<strong>视点方向</strong>，H是<strong>L和V夹角的角平分线方向</strong>：</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/av*BmblJYVfKfA5gt1yy.*jlejNBqbh6pnKPSDKwTxg!/r/dLkAAAAAAAAA&amp;bo=5QKwAeUCsAEDCSw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545880972455"></p><ol><li>漫反射（Diffuse reflection）：</li></ol><p>漫反射光的传播是各向同性的（isotropic）。</p><p><strong>漫反射光强度公式</strong>：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I_d = I_i * K_d * ( L · <span class="keyword">N</span> )</span><br></pre></td></tr></table></figure><p>其中，Kd是<strong>漫反射系数</strong>，Kd有RGB三个独立的通道，与模型本身色彩相关。I_i是<strong>入射光光强</strong>。</p><p>L · N是点积，表示<strong>入射光与法向量的夹角</strong>越小，则漫反射光越强，反之则越弱。</p><ol start="2"><li>镜面反射光（Specular reflection）：</li></ol><p>根据反射定律，反射光往往集中在一个小的立体角内，这些反射光称为镜面反射光。</p><p><strong>镜面反射光强度公式</strong>：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I_s = I_i * K_s * ( R · V )^n</span><br></pre></td></tr></table></figure><p>其中，Ks是<strong>镜面反射系数</strong>，与物体的表面光滑程度相关。n是<strong>反射指数</strong>，n越大，高光区域越集中。</p><p>R · V是点积，表示<strong>反射光和视点方向的夹角</strong>越小，则镜面反射光越强，反之越弱。</p><ol start="3"><li>环境光反射（Ambient reflection）：</li></ol><p><strong>环境光反射光强度公式</strong>：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">I_a = I_i * K_a</span><br></pre></td></tr></table></figure><p>其中，Ka是物体对环境光的反射系数常数。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/qk447.l0.ZWNvZ9GAM*c9y8coOtF7jtEnWLWa4aTnVg!/r/dDcBAAAAAAAA&amp;bo=TQPnAU0D5wEDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545889622242"></p><p>改动系数，体会各系数对模型的影响，如下图所示。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/UyrgHoY1Ubacm9VrELU8izPZZlU.uFozE1TuXiWrcZ4!/r/dLsAAAAAAAAA&amp;bo=NAK2ATQCtgEDORw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545889634936"></p><ul><li>Phong和Gouraud明暗处理（Shading）？</li></ul><p><strong>Gouraud Shading</strong>：1971年提出色彩插值，计算模型顶点颜色，然后根据顶点颜色按重心插值（Barycentric Interpolation），赋予色彩。</p><p><strong>Phong Shading</strong>：1973年提出法向插值，计算顶点法向，然后根据顶点法向插值，得到连续的法向量场，然后三角形上每一点都用Phong模型计算色彩。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/HecdACxc9Bpz7WifEPMoL6r1c4Zd6sYvfyWp5mBh0wI!/r/dLYAAAAAAAAA&amp;bo=BwPAAQcDwAEDKQw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545889746636"></p><h3 id="2-4-视点变换和视点方向"><a href="#2-4-视点变换和视点方向" class="headerlink" title="2.4 视点变换和视点方向"></a>2.4 视点变换和视点方向</h3><ul><li>四种简单变换（Simple Transformations）？</li></ul><p>Identity(不变) , translation(平移), rotation(旋转) and isotropic scaling(均衡缩放)</p><ul><li>常见的变换有哪些？</li></ul><p>都是由简单变换组合复合起来。</p><p>Rigid-body Transformation (刚体变换)：保持度量（长度、角度、大小）；不变、平移、旋转</p><p>Similarity Transformation(相似变换)：保持角度；不变、平移、旋转、均衡缩放</p><p>Linear Transformation(线性变换)：满足线性方程；不变、旋转、缩放（不只是均衡缩放）、对称、错切</p><p>Affine Transformation(仿射变换)：保持直线平行；线性变换、相似变换</p><p>Projective Transformation(投影变换)：</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/eTm0iklkUT.Vy.n1Q3a3AC0h76h*FgBwraWb8.DgN9E!/r/dL8AAAAAAAAA&amp;bo=jgPzAY4D8wEDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545890872169"></p><ul><li>什么是齐次坐标？</li></ul><p><strong>齐次坐标</strong>（homogenous coordinates）的本质是使用四维数组来表示三维空间的点和向量。</p><ul><li>怎么保证变换后法向量的正确性？</li></ul><p>变换<strong>切平面</strong>（tangent plane），再通过切平面计算法向量，而不是直接计算。新的法向量n_WS计算方法如下。其中M是变换矩阵。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/05qmf6LS9H8JG*kZgbrLiWl0zJz1MKp*1GtoHyHnqIQ!/r/dFIBAAAAAAAA&amp;bo=bgMFAm4DBQIDCSw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1545893136853"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这一章主要从&lt;strong&gt;颜色和光的基本概念&lt;/strong&gt;，扩展到色彩空间的概念，详细介绍了几个常用的&lt;strong&gt;色彩空间&lt;/strong&gt;。然后讲解了一些&lt;strong&gt;图像&lt;/strong&gt;的基本知识，最后讲了一些&lt;strong&gt;光照模型&lt;/strong&gt;的知识。主要是一些零散的概念，为后面的知识作铺垫。&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="色彩空间" scheme="http://yhcheer.com/tags/%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4/"/>
    
      <category term="图像基础" scheme="http://yhcheer.com/tags/%E5%9B%BE%E5%83%8F%E5%9F%BA%E7%A1%80/"/>
    
      <category term="光照模型" scheme="http://yhcheer.com/tags/%E5%85%89%E7%85%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>【《计算机图形学基础》提炼总结】（一）简介、历史与现状</title>
    <link href="http://yhcheer.com/2018/12/27/graph-note-01/"/>
    <id>http://yhcheer.com/2018/12/27/graph-note-01/</id>
    <published>2018-12-26T16:08:00.000Z</published>
    <updated>2018-12-29T06:54:29.259Z</updated>
    
    <content type="html"><![CDATA[<p>第一章主要讲解了<strong>计算机图形学的基本概念</strong>，包括定义以及和另一些相近研究方向的区别，并详细讲解了计算机图形学的<strong>历史与发展进程</strong>，最后展示了<strong>最新的图形学研究成果</strong>。作为绪论的一章，重在引起同学们的兴趣。</p><a id="more"></a><p>课程主页：<a href="https://cg.cs.tsinghua.edu.cn/course/resource.htm" target="_blank" rel="noopener">https://cg.cs.tsinghua.edu.cn/course/resource.htm</a></p><p>本系列笔记导航：<a href="http://yhcheer.com/2018/12/21/graph-note/">http://yhcheer.com/2018/12/21/graph-note/</a></p><h2 id="第一讲-图形学简介"><a href="#第一讲-图形学简介" class="headerlink" title="第一讲 图形学简介"></a>第一讲 图形学简介</h2><ul><li>什么是计算机图形学？</li></ul><p><strong>计算机图形学</strong>是利用计算机研究图形的表示、生成、处理、显示的学科。</p><p>Computer Graphics is a subject to investigate graphics representation, generation, processing and display by using Computers.</p><ul><li>图形和图像的区别？</li></ul><p><strong>图像</strong>（Image）：计算机内以位图（Bitmap）形式存在的灰度信息。</p><p><strong>图形</strong>（Graph）：场景的几何模型+景物的物理属性，如模型本身+颜色+光照属性+反射率等。主要分为基于线条表示的图形和明暗图（Shading）。</p><ul><li>计算机图形学和CAD的历史？</li></ul><p>In 1962, MIT’s Lincoln Lab, Ivan Sutherland’s PhD Thesis  Sketchpad: <strong><em>A Man-Machined Graphical Communication System</em></strong></p><p>Professor Coons, the concept of “<strong>CAD</strong>” (Computer Aided Design) in 1958, Coons surface in 1964, Coons Award</p><ul><li>计算机图形学与模式识别、计算机视觉、数字图像处理的关系？</li></ul><p><strong>计算机图形学</strong>（Computer Graphics）输入的是对虚拟场景的描述，通常为多边形数组，而每个多边形由各个顶点组成，每个顶点包括三维坐标、贴图坐标、rgb颜色等。输出的是图像，即二维像素数组。</p><p><strong>模式识别</strong>（Pattern Recognition）的重点在于识别和理解的过程，指计算机图形学进行识别和分辨的描述，是从图形到描述的表达过程，其本质是分类。</p><p><strong>计算机视觉</strong>（Computer Vision）输入的是图像，通常来自相机。输出的是对于图像对应的真实世界的理解，比如检测人脸、识别车牌。计算机图形学与计算机视觉是互逆问题。</p><p><strong>数字图像处理</strong>（Digital Image Processing）输入的是图像，输出的也是图像，对已有的图像进行变换、分析、重构。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;第一章主要讲解了&lt;strong&gt;计算机图形学的基本概念&lt;/strong&gt;，包括定义以及和另一些相近研究方向的区别，并详细讲解了计算机图形学的&lt;strong&gt;历史与发展进程&lt;/strong&gt;，最后展示了&lt;strong&gt;最新的图形学研究成果&lt;/strong&gt;。作为绪论的一章，重在引起同学们的兴趣。&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>【《计算机图形学基础》提炼总结】开篇&amp;导航</title>
    <link href="http://yhcheer.com/2018/12/21/graph-note/"/>
    <id>http://yhcheer.com/2018/12/21/graph-note/</id>
    <published>2018-12-21T07:30:00.000Z</published>
    <updated>2018-12-29T13:49:45.147Z</updated>
    
    <content type="html"><![CDATA[<p>由清华大学胡事民教授的<strong>《计算机图形学基础》</strong>课程教案中，个人提取出的一些<strong>学习笔记</strong>。<strong>主要内容</strong>包括：图形学简介、颜色模型、图像基本知识、Phong光照模型、视图模型变换、材质反射属性模型BRDF、光线跟踪、Bezier曲线曲面、B样条曲线曲面、网格、光线跟踪加速算法、纹理、阴影生成等。本文主要以QA的形式进行总结。</p><a id="more"></a><p>课程主页：<a href="https://cg.cs.tsinghua.edu.cn/course/resource.htm" target="_blank" rel="noopener">https://cg.cs.tsinghua.edu.cn/course/resource.htm</a></p><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p><a href="http://yhcheer.com/2018/12/21/graph-note-01/">第一讲 图形学简介、历史</a></p><p><a href="http://yhcheer.com/2018/12/21/graph-note-02/">第二讲 颜色模型、图像基本知识、Phong光照模型</a></p><p>第三讲 材质反射属性模型BRDF</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由清华大学胡事民教授的&lt;strong&gt;《计算机图形学基础》&lt;/strong&gt;课程教案中，个人提取出的一些&lt;strong&gt;学习笔记&lt;/strong&gt;。&lt;strong&gt;主要内容&lt;/strong&gt;包括：图形学简介、颜色模型、图像基本知识、Phong光照模型、视图模型变换、材质反射属性模型BRDF、光线跟踪、Bezier曲线曲面、B样条曲线曲面、网格、光线跟踪加速算法、纹理、阴影生成等。本文主要以QA的形式进行总结。&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="清华大学" scheme="http://yhcheer.com/tags/%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>学习OpenGL道路上的所见所闻</title>
    <link href="http://yhcheer.com/2018/11/17/learn-opengl/"/>
    <id>http://yhcheer.com/2018/11/17/learn-opengl/</id>
    <published>2018-11-17T09:06:00.000Z</published>
    <updated>2018-12-29T06:54:58.739Z</updated>
    
    <content type="html"><![CDATA[<p>所见即所闻。施工中…</p><a id="more"></a><h2 id="一、环境搭建"><a href="#一、环境搭建" class="headerlink" title="一、环境搭建"></a>一、环境搭建</h2><p><strong>记录下自己使用的环境搭建过程（备忘）：Win10+VS2017+glfw+glew</strong></p><p>修改三个位置C++常规、链接器常规、输入</p><ol><li>C/C++-常规-附加包含目录</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">C:\Develop\OpenGL\glew-2.1.0-win32\glew-2.1.0\include</span><br><span class="line">C:\Develop\OpenGL\glfw-3.2.1.bin.WIN32\glfw-3.2.1.bin.WIN32\include</span><br><span class="line">C:\Develop\OpenGL\glm-0.9.8.5\glm</span><br></pre></td></tr></table></figure><p>注意：glm只有头文件，没有库</p><ol start="2"><li>链接器-常规-附加库目录</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">C:\Develop\OpenGL\glew-2.1.0-win32\glew-2.1.0\lib\Release\Win32</span><br><span class="line">C:\Develop\OpenGL\glfw-3.2.1.bin.WIN32\glfw-3.2.1.bin.WIN32\lib-vc2015</span><br></pre></td></tr></table></figure><ol start="3"><li>链接器-输入-附加依赖项</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opengl32.lib</span><br><span class="line">glfw3.lib</span><br><span class="line">glew32s.lib</span><br></pre></td></tr></table></figure><h2 id="二、OpenGL运作流程"><a href="#二、OpenGL运作流程" class="headerlink" title="二、OpenGL运作流程"></a>二、OpenGL运作流程</h2><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542447163022.png" alt="1542447163022"></p><ul><li>VAO&amp;VBO&amp;EBO</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542449853303.png" alt="1542449853303"></p><ul><li>官方文档VAO&amp;VBO&amp;EBO</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542450985371.png" alt="1542450985371"></p><h2 id="3-Hello-Shaders"><a href="#3-Hello-Shaders" class="headerlink" title="3. Hello Shaders"></a>3. Hello Shaders</h2><ul><li>shaders的输入与输出</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542453603179.png" alt="1542453603179"></p><ul><li>写第一个shader，颜色设为暗红色</li></ul><p><img src="C:\Users\yh\Pictures\5.png" alt=""></p><ul><li>Uniform的应用，图形背景为会呼吸渐变的绿色</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542460859488.png" alt="1542460859488"></p><ul><li>VBO内存内部数据，添加顶点颜色数据</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542462561030.png" alt="1542462561030"></p><ul><li>读取文件的操作示意图</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542471264896.png" alt="1542471264896"></p><h2 id="4-Hello-Texture"><a href="#4-Hello-Texture" class="headerlink" title="4. Hello Texture"></a>4. Hello Texture</h2><ul><li>导入纹理</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542521791170.png" alt="1542521791170"></p><ul><li>纹理*顶点颜色</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542521654452.png" alt="1542521654452"></p><ul><li>纹理滑动通道槽</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542523870101.png" alt="1542523870101"></p><ul><li>两个纹理合并</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542536644772.png" alt="1542536644772"></p><h2 id="5-Transform"><a href="#5-Transform" class="headerlink" title="5. Transform"></a>5. Transform</h2><ul><li><p>旋转90度，并缩放0.5倍</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542538546792.png" alt="1542538546792"></p></li></ul><h3 id="6-Coordinate-System"><a href="#6-Coordinate-System" class="headerlink" title="6. Coordinate System"></a>6. Coordinate System</h3><ul><li><p>MVC坐标</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542546003428.png" alt="1542546003428"></p></li><li><p>MVC</p><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542557834664.png" alt="1542557834664"></p></li><li><p>透视矩阵</p></li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542547403533.png" alt="1542547403533"></p><ul><li>生成立方体并旋转+Z缓冲</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542551516693.png" alt="1542551516693"></p><ul><li>多个立方体</li></ul><p><img src="C:\Users\yh\AppData\Roaming\Typora\typora-user-images\1542552392750.png" alt="1542552392750"></p><p>参考：</p><p>LearnOpenGL中文文档：<a href="https://learnopengl-cn.github.io/" target="_blank" rel="noopener">https://learnopengl-cn.github.io/</a></p><p>傅老師/OpenGL教學：<a href="https://www.bilibili.com/video/av24353839" target="_blank" rel="noopener">https://www.bilibili.com/video/av24353839</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;所见即所闻。施工中…&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="OpenGL" scheme="http://yhcheer.com/tags/OpenGL/"/>
    
      <category term="C++" scheme="http://yhcheer.com/tags/C/"/>
    
      <category term="学习笔记" scheme="http://yhcheer.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop集群下的MapReduce实现</title>
    <link href="http://yhcheer.com/2018/11/01/hadoop-mapreduce/"/>
    <id>http://yhcheer.com/2018/11/01/hadoop-mapreduce/</id>
    <published>2018-11-01T07:15:00.000Z</published>
    <updated>2018-12-21T07:39:15.566Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章记录<strong>MapReduce</strong>的编程和实现，语言用的是<strong>JAVA</strong>。</p><p>搭环境的时候我们用hadoop自带的<strong>wordcount</strong> example来当作HelloWorld测试环境是否成功搭建，现在我们手撸MapReduce，同样从<strong>HelloWorld</strong>开始。</p><a id="more"></a><p>导包，这里我新建maven工程，把包交由maven管理，记得改成你安装的hadoop版本和jdk版本。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.hdp<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>wordcount<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">hadoopVersion</span>&gt;</span>2.7.7<span class="tag">&lt;/<span class="name">hadoopVersion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Hadoop start --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoopVersion&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-hdfs<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoopVersion&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-mapreduce-client-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoopVersion&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoopVersion&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- Hadoop end --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jdk.tools<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">scope</span>&gt;</span>system<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">systemPath</span>&gt;</span>$&#123;JAVA_HOME&#125;/lib/tools.jar<span class="tag">&lt;/<span class="name">systemPath</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">source</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">source</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">target</span>&gt;</span>1.8<span class="tag">&lt;/<span class="name">target</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure><p>一个MapReduce由三部分组成。新建如下三个类，最后打成jar包。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * k3：单词 -&gt; v3：记录个数列表(1,1,1...)</span></span><br><span class="line"><span class="comment"> * k4：单词 -&gt; v4：个数统计</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key3, Iterable&lt;IntWritable&gt; value3, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * context 是Reduce的上下文</span></span><br><span class="line"><span class="comment">         * 上文：mapper</span></span><br><span class="line"><span class="comment">         * 下文：HDFS</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(IntWritable val : value3)&#123;</span><br><span class="line">            sum += val.get();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        result.set(sum);</span><br><span class="line">        context.write(key3, result); <span class="comment">//k3 == k4，输出k4 -&gt; v4</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *  k1: 偏移量 -&gt; v1：数据（每行）</span></span><br><span class="line"><span class="comment"> *  k2：数据（每个单词） -&gt; v2：记单词个数1</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key1, Text value1, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        Context上下文</span></span><br><span class="line"><span class="comment">        上文：HDFS</span></span><br><span class="line"><span class="comment">        下文：Reduce</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        String data = value1.toString();</span><br><span class="line"></span><br><span class="line">        StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(data);<span class="comment">//分解字符串</span></span><br><span class="line">        <span class="keyword">while</span> (itr.hasMoreTokens())&#123;</span><br><span class="line">            word.set(itr.nextToken());<span class="comment">//更新k2</span></span><br><span class="line">            context.write(word, one); <span class="comment">//利用上下文进行输出 k2 -&gt; v2</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(otherArgs.length != <span class="number">2</span>)&#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt;"</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//创建一个任务，并指定入口</span></span><br><span class="line">        Job job = <span class="keyword">new</span> Job(conf, <span class="string">"word count"</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        <span class="comment">//指定任务map，及map输出的类型&lt;k2,v2&gt;</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);<span class="comment">//k2</span></span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);<span class="comment">//v2</span></span><br><span class="line">        <span class="comment">//指定任务reduce</span></span><br><span class="line">        job.setCombinerClass(WordCountReducer.class);<span class="comment">//优化，相当于本地的Reduce</span></span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);<span class="comment">//k4</span></span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);<span class="comment">//v4</span></span><br><span class="line">        <span class="comment">//输入输出路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));<span class="comment">//注意导新API的包</span></span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">        <span class="comment">//执行任务</span></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>)?<span class="number">0</span>:<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>参考：</p><p>Hadoop所需jar包：<a href="https://blog.csdn.net/qq_33813365/article/details/70214484" target="_blank" rel="noopener">https://blog.csdn.net/qq_33813365/article/details/70214484</a></p><p>TopK：<a href="https://www.imooc.com/article/details/id/20699#comment" target="_blank" rel="noopener">https://www.imooc.com/article/details/id/20699#comment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇文章记录&lt;strong&gt;MapReduce&lt;/strong&gt;的编程和实现，语言用的是&lt;strong&gt;JAVA&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;搭环境的时候我们用hadoop自带的&lt;strong&gt;wordcount&lt;/strong&gt; example来当作HelloWorld测试环境是否成功搭建，现在我们手撸MapReduce，同样从&lt;strong&gt;HelloWorld&lt;/strong&gt;开始。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://yhcheer.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://yhcheer.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://yhcheer.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="MapReduce" scheme="http://yhcheer.com/tags/MapReduce/"/>
    
      <category term="Java" scheme="http://yhcheer.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>用阿里云搭建Hadoop集群</title>
    <link href="http://yhcheer.com/2018/10/23/hadoop-from-zero/"/>
    <id>http://yhcheer.com/2018/10/23/hadoop-from-zero/</id>
    <published>2018-10-23T14:10:33.000Z</published>
    <updated>2018-12-21T07:39:44.893Z</updated>
    
    <content type="html"><![CDATA[<p>随着云服务器的飞速发展，伴随着<strong>云平台</strong>的各种巨大优势所在，在云上<strong>配置Hadoop集群</strong>似乎是最正确的选择。</p><p>这次用了3台<strong>阿里云ECS服务器</strong>（学生机）来完成这次的环境搭建。由于是三个不同的账号（每个账号的学生优惠只能有一个实例），所以走的是<strong>外网IP通道</strong>，和网上大部分教程有一定的区别。</p><a id="more"></a><h2 id="一、HADOOP集群搭建"><a href="#一、HADOOP集群搭建" class="headerlink" title="一、HADOOP集群搭建"></a>一、HADOOP集群搭建</h2><h3 id="1-服务器准备"><a href="#1-服务器准备" class="headerlink" title="1 服务器准备"></a>1 服务器准备</h3><p>阿里云ESC服务器 1 vCPU 2 GB (I/O优化) ecs.n4.small 1Mbps </p><p>默认系统选的Centos 7.4 64bit</p><p>阿里云已经导入学信网系统，学生优惠9.5/月，你值得拥有</p><h3 id="2-网络环境准备"><a href="#2-网络环境准备" class="headerlink" title="2 网络环境准备"></a>2 网络环境准备</h3><p>阿里云自动分配公网IP和私网IP，记住即可</p><p>阿里云的安全组设置默认只开启22端口用于SSH，以及3389端口用于远程登录</p><p>对于搭hadoop集群的我们肯定是不够的，如果你不太了解hadoop的端口配置，就到阿里云控制台上在你的实例的安全组上，添加如下一步到位的规则：</p><p>规则方向-出方向和入方向，协议类型-全部，授权类型-地址段访问，授权对象-0.0.0.0/0</p><p>当然这样是很不安全的，但对于新手来说，省了很多麻烦，建议后期手动修改安全组设置。</p><h3 id="3-服务器系统设置"><a href="#3-服务器系统设置" class="headerlink" title="3 服务器系统设置"></a>3 服务器系统设置</h3><p>3.1 添加HADOOP用户</p><p><del>不添加。</del>我是用root用户来搭建。</p><p><strong>PS. 我第一次搭的时候，使用的是HADOOP用户，但尝试了各种方法，都无法成功在HADOOP用户下进行ssh免密，导致最后跑集群的时候出错。</strong></p><p>3.2 分配root权限</p><p><del>root用户无需再分配</del></p><p>3.3 同步时间</p><p><del>阿里云无需同步时间</del></p><p>3.4 设置主机名（重要）</p><p><code>sudo nano /etc/hostname</code></p><p>我习惯用nano，没有的话装一下<code>yum install nano</code></p><p>如果是自己的主机的话直接在“阿里云实例设置-修改信息-重启实例”也能改。</p><p>三台机器主机名分别设y为：</p><ul><li>hdp-node-01</li><li>hdp-node-02</li><li>hdp-node-03</li></ul><p>3.5 域名映射（重要）</p><p>将一些常用的网址域名与其对应的IP地址建立一个关联“数据库”</p><p><code>sudo nano /etc/hosts</code></p><p>在<strong>文件最下方</strong>添加如下信息，我这里用外网IP。如果是在同一个账号下的三个实例，可以选择走内网IP通道，速度上应该会快很多。</p><ul><li>本机<strong>内网IP</strong> hdp-node-01</li><li>从机外网IP hdp-node-02</li><li>从机外网IP hdp-node-03</li></ul><p><strong>PS. 这里一开始我用的都是外网IP，最后报错，原因大概是阿里云的外网IP冲突问题，因此改为内网IP。注意只有主机的hosts配置的第一个节点（本机）是内网IP，并且另外几台从机的hosts配置都是使用外网IP不用改变。</strong></p><p>3.6 配置ssh免密登录（重要）</p><p><code>ssh-keygen</code>利用ssh-keygen生成密钥</p><p><code>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</code>加入到授权，可以免密ssh自己</p><p>把密匙公钥发送给别的节点，已达到免密的效果，发送时要输入对面节点的密码</p><p><code>scp ~/.ssh/id_rsa.pub root@hdp-node-02:~/.ssh</code>将id_rsa.pub拷贝到hdp-node-02节点上</p><p><code>scp ~/.ssh/id_rsa.pub root@hdp-node-03:~/.ssh</code>将id_rsa.pub拷贝到hdp-node-03节点上</p><p><strong>换到hdp-node-02和hdp-node-03上操作：</strong></p><p><code>cat ~/.ssh/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</code>把刚才的密匙加入到授权</p><p><strong>回到hdp-node-01上操作：</strong></p><p>测试<code>ssh hdp-node-02</code>成功！如果还需要输入密码则免密失败。</p><p><code>logout</code>退出刚才的ssh</p><p><strong>PS. 后来调试bug的时候，我把所有节点相互之间的ssh免密也实现了，理论上应该只需要主机ssh所有从机即可。</strong></p><p>3.7 配置防火墙</p><p><code>systemctl stop firewalld</code>关闭centos7防火墙</p><h3 id="4-JDK环境安装"><a href="#4-JDK环境安装" class="headerlink" title="4 JDK环境安装"></a>4 JDK环境安装</h3><p>JDK是HADOOP的必要环境</p><p>下载jdk1.8，可以用wget方法，我就用FileZilla传上去再解压好了</p><p>放到/usr文件夹下，解压</p><p><code>tar -zxf jdk-8u191-linux-x64.tar.gz</code></p><p>重命名一下文件夹名字为java（非必须）</p><p><code>mv jdk1.8.0_191 java</code></p><p>配置环境变量<code>nano /etc/profile</code>，在<strong>文件最下方</strong>添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java</span><br><span class="line">export PATH=$JAVA_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><p>生效环境<code>source /etc/profile</code></p><p>测试<code>java -version</code>，成功则显示版本号</p><p>重复以上步骤在每个从机上执行</p><h3 id="5-hadoop安装和部署"><a href="#5-hadoop安装和部署" class="headerlink" title="5 hadoop安装和部署"></a>5 hadoop安装和部署</h3><p>下载、解压。同上。</p><p>重命名一下（非必须）</p><p><code>mv hadoop2.7.7 hadoop</code></p><p><strong>PS. 我这里使用的是hadoop 2.7.7版本，注意hadoop 3与hadoop 2的改动比较大，包括端口、命令、以及一些配置等，注意区别。</strong></p><p>配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java</span><br><span class="line">export PATH=PATH:$JAVA_HOME/bin</span><br><span class="line">export HADOOP_HOME=/usr/hadoop</span><br><span class="line">export PATH=PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><p>生效环境<code>source /etc/profile</code></p><p>测试<code>hadoop version</code>显示版本号，则成功</p><h3 id="6-开始部署hadoop"><a href="#6-开始部署hadoop" class="headerlink" title="6 开始部署hadoop"></a>6 开始部署hadoop</h3><p>进入hadoop安装目录下的<strong>子目录</strong>/etc/hadoop</p><p><code>cd /usr/hadoop/etc/hadoop</code></p><ul><li>配置JAVA路径</li></ul><p><code>nano hadoop-env.sh</code>找到下面写有JAVA_HOME的地方，修改JAVA路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># The java implementation to use.</span><br><span class="line">export JAVA_HOME=/usr/java</span><br></pre></td></tr></table></figure><ul><li>配置core-site.xml</li></ul><p>集群全局参数，用于定义系统级别的参数，如HDFS  URL、Hadoop的临时目录等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hdp-node-01:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>fs.defaultFS</td><td>file:///</td><td>文件系统主机和端口</td></tr><tr><td>2</td><td>io.file.buffer.size</td><td>4096</td><td>流文件的缓冲区大小</td></tr><tr><td>3</td><td>hadoop.tmp.dir</td><td>/tmp/hadoop-${user.name}</td><td>临时文件夹</td></tr></tbody></table><ul><li>配置hdfs-site.xml</li></ul><p>HDFS参数，如名称节点和数据节点的存放位置、文件副本的个数、文件读取权限等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-02:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.https-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-02:50091<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>dfs.namenode.secondary.http-address</td><td>0.0.0.0:50090</td><td>定义HDFS对应的HTTP服务器地址和端口</td></tr><tr><td>2</td><td>dfs.namenode.name.dir</td><td>file://${hadoop.tmp.dir}/dfs/name</td><td>定义DFS的名称节点在本地文件系统的位置</td></tr><tr><td>3</td><td>dfs.datanode.data.dir</td><td>file://${hadoop.tmp.dir}/dfs/data</td><td>定义DFS数据节点存储数据块时存储在本地文件系统的位置</td></tr><tr><td>4</td><td>dfs.replication</td><td>3</td><td>缺省的块复制数量</td></tr><tr><td>5</td><td>dfs.webhdfs.enabled</td><td>true</td><td>是否通过http协议读取hdfs文件，如果选是，则集群安全性较差</td></tr></tbody></table><ul><li>配置mapred-site.xml</li></ul><p>Mapreduce参数，包括JobHistory Server和应用程序参数两部分，如reduce任务的默认个数、任务所能够使用内存的默认上下限等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>mapreduce.framework.name</td><td>local</td><td>取值local、classic或yarn其中之一，如果不是yarn，则不会使用YARN集群来实现资源的分配</td></tr><tr><td>2</td><td>mapreduce.jobhistory.address</td><td>0.0.0.0:10020</td><td>定义历史服务器的地址和端口，通过历史服务器查看已经运行完的Mapreduce作业记录</td></tr><tr><td>3</td><td>mapreduce.jobhistory.webapp.address</td><td>0.0.0.0:19888</td><td>定义历史服务器web应用访问的地址和端口</td></tr></tbody></table><ul><li>配置yarn-site.xml</li></ul><p>集群资源管理系统参数，配置 ResourceManager，NodeManager 的通信端口，web监控端口等</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- RM的hostname --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定Yarn的老大(ResourceManager)的地址--&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>序号</th><th>参数名</th><th>默认值</th><th>参数解释</th></tr></thead><tbody><tr><td>1</td><td>yarn.resourcemanager.address</td><td>0.0.0.0:8032</td><td>ResourceManager 提供给客户端访问的地址。客户端通过该地址向RM提交应用程序，杀死应用程序等</td></tr><tr><td>2</td><td>yarn.resourcemanager.scheduler.address</td><td>0.0.0.0:8030</td><td>ResourceManager提供给ApplicationMaster的访问地址。ApplicationMaster通过该地址向RM申请资源、释放资源等</td></tr><tr><td>3</td><td>yarn.resourcemanager.resource-tracker.address</td><td>0.0.0.0:8031</td><td>ResourceManager 提供给NodeManager的地址。NodeManager通过该地址向RM汇报心跳，领取任务等</td></tr><tr><td>4</td><td>yarn.resourcemanager.admin.address</td><td>0.0.0.0:8033</td><td>ResourceManager 提供给管理员的访问地址。管理员通过该地址向RM发送管理命令等。</td></tr><tr><td>5</td><td>yarn.resourcemanager.webapp.address</td><td>0.0.0.0:8088</td><td>ResourceManager对web 服务提供地址。用户可通过该地址在浏览器中查看集群各类信息</td></tr><tr><td>6</td><td>yarn.nodemanager.aux-services</td><td></td><td>通过该配置项，用户可以自定义一些服务，例如Map-Reduce的shuffle功能就是采用这种方式实现的，这样就可以在NodeManager上扩展自己的服务。</td></tr></tbody></table><ul><li>配置slaves</li></ul><p><code>nano slaves</code></p><p>hdp-node-02<br>hdp-node-03</p><ul><li>配置masters</li></ul><p><code>nano masters</code></p><p>hdp-node-01</p><p><strong>PS. 其实可以在一台机子上安装和配置好，然后用scp命令直接复制整个文件夹给从机。但阿里云外网IP间传输实在是太慢了！</strong></p><h3 id="7-启动集群"><a href="#7-启动集群" class="headerlink" title="7 启动集群"></a>7 启动集群</h3><ul><li>初始化HDFS</li></ul><p><code>hdfs namenode -format</code></p><ul><li>启动HDFS以及YARN</li></ul><p><code>bash start-all.sh</code></p><p>集群启动完毕。在浏览器上可观察启动状况</p><p>输入<code>主机IP:50070</code>，查看大体配置情况。主要注意存活节点数，我这里是2个slaves。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/YO1pjbypw23F1YFsj3JSKcg4a.enRUaPLDcVt6RdU.I!/r/dDQBAAAAAAAA&amp;bo=rwV5Aq8FeQIDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1540315053705"></p><p>输入<code>主机IP:8088</code>，可查看当前运行情况。这里我在跑一个wordcount的demo，可看到进度情况。</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/nJKXAMQNX*dYe1n4jm9jt9yYVEBRuovkAkXj6FjZNFM!/r/dGcBAAAAAAAA&amp;bo=OAeAAngHlgIDCXo!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1540314812172"></p><ul><li>建立input目录</li></ul><p><code>hadoop fs -mkdir -p /wordcount/input</code></p><ul><li>放入文件到该目录下</li></ul><p><code>hadoop fs -put /usr/hello.txt /wordcount/input</code></p><ul><li>跑demo</li></ul><p><code>cd ./share/hadoop/mapreduce/</code></p><p><code>hadoop jar hadoop-mapreduce-examples-2.7.7.jar wordcount /wordcount/input/hello.txt output2</code></p><p>在控制台中可看到，表示运行成功：</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/UVHTTWylwbde3iwZgxsUSq7YiFS1bdv.n6*I6Ptpj*c!/r/dDcBAAAAAAAA&amp;bo=sgNtAbIDbQEDGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1540315291480"></p><p>我的hello.txt的内容是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br><span class="line">Hello World Bye World</span><br></pre></td></tr></table></figure><p>取出wordcount统计结果：</p><p><img src="//r.photo.store.qq.com/psb?/V10ldIv84XBZXi/JkLrC2ZsvrSocWq43DnOHOi08v5BYr46qzCDYUTzlXU!/r/dEgBAAAAAAAA&amp;bo=OANVADgDVQADGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1540315844610"></p><p>这就是Hadoop世界的HelloWorld代码，我们环境搭建也随之完成。</p><p>参考：</p><p>阿里云内网IP搭建：<a href="https://blog.csdn.net/bqw18744018044/article/details/79103931" target="_blank" rel="noopener">https://blog.csdn.net/bqw18744018044/article/details/79103931</a></p><p>阿里云内网IP搭建：<a href="https://blog.csdn.net/QianZhaoVic/article/details/83150703" target="_blank" rel="noopener">https://blog.csdn.net/QianZhaoVic/article/details/83150703</a></p><p>hadoop参数：<a href="https://blog.csdn.net/lydia88/article/details/79449656" target="_blank" rel="noopener">https://blog.csdn.net/lydia88/article/details/79449656</a></p><h2 id="二、基于HIVE的数据分析环境搭建"><a href="#二、基于HIVE的数据分析环境搭建" class="headerlink" title="二、基于HIVE的数据分析环境搭建"></a>二、基于HIVE的数据分析环境搭建</h2><p>因为课程作业环境的需求，这一次要基于HADOOP集群正常运行情况下，使用HIVE等工具进行数据分析，因此在hadoop集群搭建完成的基础上，安装Hive+Sqoop+HBASE+mysql。衔接上面的内容。</p><p>先到镜像站下载所需安装包：<a href="http://mirror.bit.edu.cn/apache/" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/</a><br>总结下我目前现在安装的各个环境的版本</p><ul><li>jdk-8u191-linux-x64.tar.gz</li><li>hadoop-2.7.7.tar.gz</li><li>hbase-1.3.2.1-bin.tar.gz</li><li>apache-hive-2.3.3-bin.tar.gz</li><li>sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</li><li>mysql 4.6.42</li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>这里以hive为例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-hive-2.3.3-bin.tar.gz -C /usr/</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv apache-hive-2.3.3-bin hive</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nano /etc/profile</span><br></pre></td></tr></table></figure><p>在下方添加，一口气配齐环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/usr/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br><span class="line">export HBASE_HOME=/usr/hbase</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br><span class="line">export SQOOP_HOME=/usr/sqoop</span><br><span class="line">export PATH=$PATH:$SQOOP_HOME/bin</span><br></pre></td></tr></table></figure><p>生效环境变量配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>到此，hbase、sqoop、hive都是这样安装，并配置系统环境变量。</p><p>然后我们开始部署。HBASE是比较独立的一个模块，我们先部署它。</p><h2 id="HBASE的部署"><a href="#HBASE的部署" class="headerlink" title="HBASE的部署"></a>HBASE的部署</h2><p>修改conf文件夹下的hbase-env.sh，找到下方部分修改java_home路径。并找到HBASE_MANAGES_ZK设为true，这里使用HBASE自带的zookeeper。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># The java implementation to use.  Java 1.7+ required.</span><br><span class="line">export JAVA_HOME=/usr/java</span><br><span class="line">...中间省略</span><br><span class="line"># Tell HBase whether it should manage it&apos;s own instance of Zookeeper or not.</span><br><span class="line">export HBASE_MANAGES_ZK=true</span><br></pre></td></tr></table></figure><p>新建一份hbase-site.xml，我的配置如下：注意hbase.zookeeper.quorum的配置，主机和从机有分歧。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">　　　　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="comment">&lt;!-- hbase存放数据目录 --&gt;</span></span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hdp-node-01:9000/opt/hbase/hbase_db<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　　　　　　<span class="comment">&lt;!-- 端口要和Hadoop的fs.defaultFS端口一致--&gt;</span></span><br><span class="line">　　　　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">　　　　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="comment">&lt;!-- 是否分布式部署 --&gt;</span></span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">　　　　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"></span><br><span class="line">　　　　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="comment">&lt;!-- list of  zookooper。--&gt;</span></span><br><span class="line">　　　　　　　　<span class="comment">&lt;!-- 这里是slaves配置的情况。had-node-01作为Hmaster节点，此处写hdp-node-01。--&gt;</span></span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdp-node-02,hdp-node-03<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">　　　　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> 　　　 </span><br><span class="line"></span><br><span class="line">　　　　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">　　　　　　 <span class="comment">&lt;!--zookooper配置、日志等的存储位置 --&gt;</span></span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hbase/zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>配置regionservers：</p><p>编辑HBASE目录下conf/regionservers   去掉默认的localhost，加入hdp-node-02、hdp-node-03，保存退出</p><p>配置完成后，启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-hbase.sh</span><br></pre></td></tr></table></figure><p>输入jps命令查看进程是否启动成功</p><p> hdp-node-01上出现HMaster、HQuormPeer，slaves上出现HRegionServer、HQuorumPeer，就是启动成功了。</p><p>运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase shell</span><br></pre></td></tr></table></figure><p>输入status命令可以看到如下内容，1个master，2 servers，则3机器全部成功启动。</p><p>并在<a href="http://hdp-node-01:16010/" target="_blank" rel="noopener">http://hdp-node-01:16010/</a> 可以看到详细信息。</p><p>接下去部署HIVE，是使用类SQL语言分析数据的必备工具。</p><h2 id="HIVE部署"><a href="#HIVE部署" class="headerlink" title="HIVE部署"></a>HIVE部署</h2><p>修改hive-env.sh文件，添加路径</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set HADOOP_HOME to point to a specific hadoop install directory</span></span><br><span class="line"> HADOOP_HOME=/usr/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hive Configuration Directory can be controlled by:</span></span><br><span class="line"> <span class="built_in">export</span> HIVE_CONF_DIR=/usr/hive/conf</span><br></pre></td></tr></table></figure><p>复制hive-default.xml.template，并重命名为hive-site.xml。Hive 系统会加载这两个配置文件。当“hive-site.xml”中的配置参数的值与“hive-default.xml”文件中不一致时，以用户自定义的为准。故hive-site.xml填写如下，其余部分可删除：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.local<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">1   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">value</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"> <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>Hive Metastore有三种配置方式，Derby、Local和Remote。</p><p>内嵌模式（Derby）使用的是内嵌的Derby数据库来存储元数据，也不需要额外起Metastore服务。这个是默认的，配置简单，但是一次只能一个客户端连接，适用于用来实验，不适用于生产环境。</p><p>这里用了Local本地元存储的方式。在生产环境中，建议用远程元存储来配置Hive Metastore。</p><p>本地元存储和远程元存储都采用外部数据库来存储元数据，目前支持的数据库有：MySQL、Postgres、Oracle、MS SQL Server。在这里我们使用MySQL。</p><p>接下来配置连接地址以及驱动，最后两个property是mysql的用户和密码。</p><p>因为使用MySQL作为存储元数据的数据库，所以需要把连接MySQL的jar包（mysql-connector-java-XXX.jar）放入到$HIVE_HOME/lib目录下。我直接用ftp传上去了。</p><p>既然配置到了mysql，下面我们就来安装配置mysql。</p><h2 id="mysql安装部署"><a href="#mysql安装部署" class="headerlink" title="mysql安装部署"></a>mysql安装部署</h2><p>确保之前未安装过mysql，若有一定要卸载干净再开始安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install mysql-server</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service mysqld start</span><br></pre></td></tr></table></figure><p>登录mysql，为Hive建立相应的MySQL账户，并赋予足够的权限</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; CREATE USER &apos;hive&apos; IDENTIFIED BY &apos;mysql&apos;;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;hive&apos;@&apos;%&apos; WITH GRANT OPTION;</span><br><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure><p>重启服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service mysql restart</span><br></pre></td></tr></table></figure><p>建立hive专用元数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; exit;</span><br><span class="line">root@hdp-node-01:~$ mysql -uhive -pmysql</span><br><span class="line">mysql&gt; create database hive;</span><br></pre></td></tr></table></figure><p>配置完成后，运行hive</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure><p>若不报错，则部署成功。</p><p>若报错为：</p><p><img src="http://r.photo.store.qq.com/psb?/V10ldIv84XBZXi/9st2MTzlQC4U09TP0LgQn8JVolbFWH0RKTOqmDg1NNM!/r/dDABAAAAAAAA&amp;bo=LgNBAC4DQQADCSw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1"></p><p>在确保mysql正确安装及运行的情况下，应该是Hive2需要hive元数据库初始化，运行：<br><code>schematool -dbType mysql -initSchema</code></p><p>若报错为2002，则为mysql服务未启动</p><p><img src="http://r.photo.store.qq.com/psb?/V10ldIv84XBZXi/n*0lmwRfjJLcGuR89q0Rj.S1K9b12bYEu0VxE2ozglI!/r/dDYBAAAAAAAA&amp;bo=LwNBAC8DQQADGTw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="2"></p><p>测试一下hive的运行情况，已经可以使用类SQL语言进行操作：</p><p><img src="http://r.photo.store.qq.com/psb?/V10ldIv84XBZXi/eSz.iOrtlapqyUD.48KvIbW.QAtmnNbHXYu1f8yZMjs!/r/dDUBAAAAAAAA&amp;bo=PQN9Az0DfQMDCSw!&amp;rf=viewer_4_yake_qzoneimgout.png" alt="1540953069204"></p><p>最后，我们配置下sqoop，以后可能会用到。</p><h2 id="Sqoop配置"><a href="#Sqoop配置" class="headerlink" title="Sqoop配置"></a>Sqoop配置</h2><p>修改sqoop-env.sh</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#Set path to where bin/hadoop is available</span><br><span class="line">export HADOOP_COMMON_HOME=/usr/hadoop</span><br><span class="line"></span><br><span class="line">#Set path to where hadoop-*-core.jar is available</span><br><span class="line">export HADOOP_MAPRED_HOME=/usr/hadoop</span><br><span class="line"></span><br><span class="line">#set the path to where bin/hbase is available</span><br><span class="line">export HBASE_HOME=/usr/hbase</span><br><span class="line"></span><br><span class="line">#Set the path to where bin/hive is available</span><br><span class="line">export HIVE_HOME=/usr/hive</span><br></pre></td></tr></table></figure><p>参考：</p><p>Hadoop+HBASE：<a href="https://www.cnblogs.com/lzxlfly/p/7221890.html" target="_blank" rel="noopener">https://www.cnblogs.com/lzxlfly/p/7221890.html</a></p><p>Hive Metastore解释：<a href="https://www.cnblogs.com/linbingdong/p/5829369.html" target="_blank" rel="noopener">https://www.cnblogs.com/linbingdong/p/5829369.html</a></p><p>mysql+Hive部署：<a href="https://www.cnblogs.com/kxdblog/p/4100263.html" target="_blank" rel="noopener">https://www.cnblogs.com/kxdblog/p/4100263.html</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着云服务器的飞速发展，伴随着&lt;strong&gt;云平台&lt;/strong&gt;的各种巨大优势所在，在云上&lt;strong&gt;配置Hadoop集群&lt;/strong&gt;似乎是最正确的选择。&lt;/p&gt;
&lt;p&gt;这次用了3台&lt;strong&gt;阿里云ECS服务器&lt;/strong&gt;（学生机）来完成这次的环境搭建。由于是三个不同的账号（每个账号的学生优惠只能有一个实例），所以走的是&lt;strong&gt;外网IP通道&lt;/strong&gt;，和网上大部分教程有一定的区别。&lt;/p&gt;
    
    </summary>
    
      <category term="大数据" scheme="http://yhcheer.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://yhcheer.com/tags/Hadoop/"/>
    
      <category term="大数据" scheme="http://yhcheer.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="http://yhcheer.com/tags/Hive/"/>
    
      <category term="Spark" scheme="http://yhcheer.com/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>实现一个光线追踪渲染器</title>
    <link href="http://yhcheer.com/2018/10/20/ray-tarcing-in-one-weekend/"/>
    <id>http://yhcheer.com/2018/10/20/ray-tarcing-in-one-weekend/</id>
    <published>2018-10-20T14:48:33.000Z</published>
    <updated>2018-12-29T13:46:32.977Z</updated>
    
    <content type="html"><![CDATA[<p>细读<strong>《Ray tracing in one weekend》</strong>，<strong>PeterShirly</strong>用C++语言加上一些简单的物理知识，带我们实现一个简单的光线追踪渲染器。这里是我用<strong>Java</strong>复现后的结果展示。每一章节工程代码已上传至<a href="https://github.com/yhcheer/RayTracingInOneWeekend" target="_blank" rel="noopener">Github</a>，具体实现的步骤和一些感悟写在了<a href="https://zhuanlan.zhihu.com/p/49943215" target="_blank" rel="noopener">知乎专栏</a>，如果有意见和建议还请指出，感谢！</p><a id="more"></a><p>上半部分：<a href="https://zhuanlan.zhihu.com/p/49943215" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/49943215</a></p><p>下半部分：<a href="https://zhuanlan.zhihu.com/p/50451925" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/50451925</a></p><h3 id="Chapter-12-Where-next"><a href="#Chapter-12-Where-next" class="headerlink" title="Chapter 12:  Where next?"></a>Chapter 12:  Where next?</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp0.jpg" alt=""></p><h3 id="Chapter-11-Defocus-Blur"><a href="#Chapter-11-Defocus-Blur" class="headerlink" title="Chapter 11:   Defocus Blur"></a>Chapter 11:   Defocus Blur</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp11.jpg" alt="cp11"></p><h3 id="Chapter-10-Positionable-camera"><a href="#Chapter-10-Positionable-camera" class="headerlink" title="Chapter 10:  Positionable camera"></a>Chapter 10:  Positionable camera</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp10.jpg" alt=""></p><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp10_2.jpg" alt=""></p><h3 id="Chapter-9-Dielectrics"><a href="#Chapter-9-Dielectrics" class="headerlink" title="Chapter 9:  Dielectrics"></a>Chapter 9:  Dielectrics</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp9.jpg" alt=""></p><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp9_2.jpg" alt=""></p><h3 id="Chapter-8-Metal"><a href="#Chapter-8-Metal" class="headerlink" title="Chapter 8:  Metal"></a>Chapter 8:  Metal</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp8.jpg" alt="cp8"></p><h3 id="Chapter-7-Diffuse-Materials"><a href="#Chapter-7-Diffuse-Materials" class="headerlink" title="Chapter 7:    Diffuse Materials"></a>Chapter 7:    Diffuse Materials</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp7.jpg" alt=""></p><h3 id="Chapter-6-Antialiasing"><a href="#Chapter-6-Antialiasing" class="headerlink" title="Chapter 6:  Antialiasing"></a>Chapter 6:  Antialiasing</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp6.jpg" alt="Cp6"></p><h3 id="Chapter-5-Surface-normals-and-multiple-objects"><a href="#Chapter-5-Surface-normals-and-multiple-objects" class="headerlink" title="Chapter 5:   Surface normals and  multiple objects."></a>Chapter 5:   Surface normals and  multiple objects.</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp5_1.jpg" alt="cp5-1"></p><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp5_3.jpg" alt=""></p><h3 id="Chapter-4-Adding-a-sphere"><a href="#Chapter-4-Adding-a-sphere" class="headerlink" title="Chapter 4:  Adding a sphere"></a>Chapter 4:  Adding a sphere</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp4.jpg" alt="CP4"></p><h3 id="Chapter-3-Rays-a-simple-camera-and-background"><a href="#Chapter-3-Rays-a-simple-camera-and-background" class="headerlink" title="Chapter 3:  Rays, a simple camera, and background"></a>Chapter 3:  Rays, a simple camera, and background</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp3.jpg" alt="Cp3"></p><h3 id="Chapter-2-The-vec3-class"><a href="#Chapter-2-The-vec3-class" class="headerlink" title="Chapter 2:   The vec3 class"></a>Chapter 2:   The vec3 class</h3><h3 id="Chapter-1：Output-an-image"><a href="#Chapter-1：Output-an-image" class="headerlink" title="Chapter 1：Output an image"></a>Chapter 1：Output an image</h3><p><img src="https://raw.githubusercontent.com/yhcheer/RayTracingInOneWeekend/master/image/Cp1.jpg" alt="cp1"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;细读&lt;strong&gt;《Ray tracing in one weekend》&lt;/strong&gt;，&lt;strong&gt;PeterShirly&lt;/strong&gt;用C++语言加上一些简单的物理知识，带我们实现一个简单的光线追踪渲染器。这里是我用&lt;strong&gt;Java&lt;/strong&gt;复现后的结果展示。每一章节工程代码已上传至&lt;a href=&quot;https://github.com/yhcheer/RayTracingInOneWeekend&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github&lt;/a&gt;，具体实现的步骤和一些感悟写在了&lt;a href=&quot;https://zhuanlan.zhihu.com/p/49943215&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知乎专栏&lt;/a&gt;，如果有意见和建议还请指出，感谢！&lt;/p&gt;
    
    </summary>
    
      <category term="图形学" scheme="http://yhcheer.com/categories/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
    
      <category term="计算机图形学" scheme="http://yhcheer.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"/>
    
      <category term="Java" scheme="http://yhcheer.com/tags/Java/"/>
    
      <category term="光线追踪" scheme="http://yhcheer.com/tags/%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA/"/>
    
      <category term="算法" scheme="http://yhcheer.com/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>故梦</title>
    <link href="http://yhcheer.com/2018/10/20/hello-world/"/>
    <id>http://yhcheer.com/2018/10/20/hello-world/</id>
    <published>2018-10-20T01:48:33.000Z</published>
    <updated>2018-12-29T13:42:05.593Z</updated>
    
    <content type="html"><![CDATA[<p>时隔9月，我的博客终于翻新了。</p><a id="more"></a><p>愿世界和平。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时隔9月，我的博客终于翻新了。&lt;/p&gt;
    
    </summary>
    
      <category term="杂谈" scheme="http://yhcheer.com/categories/%E6%9D%82%E8%B0%88/"/>
    
    
      <category term="心情" scheme="http://yhcheer.com/tags/%E5%BF%83%E6%83%85/"/>
    
  </entry>
  
</feed>
